{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "tf.keras.backend.set_floatx('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read data and create arrays**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_concatenated_csv = \"50x50.csv\"\n",
    "data = pd.read_csv(sorted_concatenated_csv)\n",
    "#data.drop(columns=['zCOM'], inplace=True)\n",
    "print(data.head())\n",
    "data['time'] = (data['mcsteps'] / 10000).astype(int)\n",
    "data = data[['time'] + [col for col in data.columns if col != 'time']]\n",
    "data.drop(columns=['mcsteps'], inplace=True)\n",
    "print(data)\n",
    "cytokine_columns = ['il8', 'il1', 'il6', 'il10', 'tnf', 'tgf']\n",
    "smallest_values = data[cytokine_columns].min()\n",
    "largest_values = data[cytokine_columns].max()\n",
    "\n",
    "print(\"Smallest values for each cytokine:\")\n",
    "print(smallest_values)\n",
    "print(\"\\nLargest values for each cytokine:\")\n",
    "print(largest_values)\n",
    "#def replace_negative_with_zero(data):\n",
    " #   num_negative_values = (data < 0).sum().sum()\n",
    "  #  data[data < 0] = 0\n",
    "\n",
    "   # return num_negative_values\n",
    "\n",
    "#cytokine_columns = ['il8', 'il1', 'il6', 'il10', 'tnf', 'tgf']\n",
    "\n",
    "#for col in cytokine_columns:\n",
    " #   num_negatives = replace_negative_with_zero(data[col])\n",
    "  #  print(f\"Number of negative values replaced with 0 in '{col}': {num_negatives}\")\n",
    "\n",
    "# define cytokines\n",
    "cytokines = ['il8', 'il1', 'il6', 'il10', 'tnf', 'tgf']\n",
    "\n",
    "# Remove brackets and convert to float\n",
    "for col in cytokines:\n",
    "    data[col] = data[col].str.strip('[]').astype(float)\n",
    "\n",
    "# get unique time values\n",
    "unique_time = data['time'].unique()\n",
    "\n",
    "arrays = {}\n",
    "\n",
    "# iterate over unique time values\n",
    "for time in unique_time:\n",
    "    # filter data for current value of time\n",
    "    data_time = data[data['time'] == time]\n",
    "    \n",
    "    # initialize 50x50x6 array for current value of time\n",
    "    array = np.zeros((50, 50, len(cytokines)))\n",
    "    \n",
    "    # get X and Y coordinates\n",
    "    x = data_time['xCOM'].astype(int)\n",
    "    y = data_time['yCOM'].astype(int)\n",
    "    \n",
    "    # get cytokine concentrations\n",
    "    concentrations = data_time[['il8', 'il1', 'il6', 'il10', 'tnf', 'tgf']].values\n",
    "    \n",
    "    # assign cytokine concentrations to corresponding position in array\n",
    "    array[x, y, :] = concentrations\n",
    "    \n",
    "    # store array for current value of time\n",
    "    arrays[time] = array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extract CellType from LatticeData**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_vtk_file(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    dimensions = None\n",
    "    cell_type_data_start = None\n",
    "    for i, line in enumerate(lines):\n",
    "        if line.startswith(\"DIMENSIONS\"):\n",
    "            dimensions = list(map(int, line.split()[1:]))\n",
    "        elif line.startswith(\"CellType\"):\n",
    "            cell_type_data_start = i + 1\n",
    "            break\n",
    "    \n",
    "    if dimensions is None or cell_type_data_start is None:\n",
    "        raise ValueError(\"Invalid VTK file format\")\n",
    "    \n",
    "    grid_data = []\n",
    "    data_lines = lines[cell_type_data_start:]\n",
    "    for line in data_lines:\n",
    "        if line.strip() and not line.startswith(\"FIELD\"):\n",
    "            try:\n",
    "                grid_data.extend(map(int, line.split()))\n",
    "                if len(grid_data) >= dimensions[0] * dimensions[1]:\n",
    "                    break\n",
    "            except ValueError:\n",
    "                continue  # Skip lines that can't be converted to int\n",
    "    \n",
    "    expected_size = dimensions[0] * dimensions[1]\n",
    "    if len(grid_data) != expected_size:\n",
    "        raise ValueError(f\"Data size {len(grid_data)} does not match expected size {expected_size}\")\n",
    "\n",
    "    grid_data = np.array(grid_data[:expected_size]).reshape((dimensions[0], dimensions[1], 1))\n",
    "    return grid_data\n",
    "\n",
    "def process_vtk_files(directory):\n",
    "    vtk_arrays = []\n",
    "    for filename in sorted(os.listdir(directory)):\n",
    "        if filename.endswith(\".vtk\"):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            grid_data = read_vtk_file(filepath)\n",
    "            vtk_arrays.append(grid_data)\n",
    "    return vtk_arrays\n",
    "\n",
    "directory = \"neural-agent-models/data/LatticeData/LatticeData(50x50)\"\n",
    "vtk_arrays = process_vtk_files(directory)\n",
    "\n",
    "# Check the 3D array for a specific coordinate and timestep\n",
    "timestep = 0  # Timestep index\n",
    "x, y = 31, 31  # Coordinates to check\n",
    "cell_type = vtk_arrays[timestep][x, y, 0]\n",
    "print(f\"The cell type at ({x}, {y}) at timestep {timestep} is {cell_type}\")\n",
    "\n",
    "# The vtk_arrays will contain all the 3D arrays for each timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vtk_arrays[0][31,31])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create binary variables from extracted CellType**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_cell_presence(vtk_arrays, start_idx, end_idx):\n",
    "    cellpresente = []\n",
    "    cellpresentndn = []\n",
    "    cellpresentna = []\n",
    "    cellpresentm1 = []\n",
    "    cellpresentm2 = []\n",
    "\n",
    "    for i in range(start_idx, end_idx + 1):\n",
    "        array = vtk_arrays[i].reshape(50, 50)\n",
    "        cellpresente.append(1 if np.any(array == 1) else 0)\n",
    "        cellpresentndn.append(1 if np.any(array == 2) else 0)\n",
    "        cellpresentna.append(1 if np.any(array == 5) else 0)\n",
    "        cellpresentm1.append(1 if np.any(array == 8) else 0)\n",
    "        cellpresentm2.append(1 if np.any(array == 9) else 0)\n",
    "    return cellpresente, cellpresentndn, cellpresentna, cellpresentm1, cellpresentm2\n",
    "\n",
    "# Adjust the range to 0-100\n",
    "cellpresente, cellpresentndn, cellpresentna, cellpresentm1, cellpresentm2 = check_cell_presence(vtk_arrays, 0, 100)\n",
    "\n",
    "# Output the results\n",
    "for t in range(0, 101):\n",
    "    idx = t  # Index directly corresponds to the timestep\n",
    "    print(f\"Timestep {t}:\")\n",
    "    print(f\"  cellpresente: {cellpresente[idx]}\")\n",
    "    print(f\"  cellpresentndn: {cellpresentndn[idx]}\")\n",
    "    print(f\"  cellpresentna: {cellpresentna[idx]}\")\n",
    "    print(f\"  cellpresentm1: {cellpresentm1[idx]}\")\n",
    "    print(f\"  cellpresentm2: {cellpresentm2[idx]}\")\n",
    "\n",
    "output_dir = \"neural-agent-models/data/PINN/Results\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "results = np.column_stack((range(0, 101), cellpresente, cellpresentndn, cellpresentna, cellpresentm1, cellpresentm2))\n",
    "np.savetxt(os.path.join(output_dir, 'cell_presence_results.csv'), results, delimiter=',', header='Timestep,cellpresente,cellpresentndn,cellpresentna,cellpresentm1,cellpresentm2', comments='', fmt='%d')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
