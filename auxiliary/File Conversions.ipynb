{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we:\n",
    " 1) do file conversions to generate .vtk files in order to generate more plots\n",
    " 2) plot the loss from the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import vtk\n",
    "import os\n",
    "import csv\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CUDA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tf.config.list_physical_devices('GPU'))>0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** .txt files generated from CompuCell3D to .csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = \"data/concentrations_txt/S8\"\n",
    "output_folder = \"data/concentrations/S8\"\n",
    "\n",
    "# create output folder if it doesn't exist\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# iterate through files in input folder\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        try:\n",
    "            # construct input and output file paths\n",
    "            input_filepath = os.path.join(input_folder, filename)\n",
    "            output_filepath = os.path.join(output_folder, os.path.splitext(filename)[0] + \".csv\")\n",
    "\n",
    "            # read txt file and remove leading and trailing quotation marks from each line\n",
    "            with open(input_filepath, 'r') as file:\n",
    "                lines = [line.strip().strip('\"') for line in file.readlines()]\n",
    "\n",
    "            # convert to df and save as csv\n",
    "            df = pd.DataFrame([line.split(',') for line in lines])\n",
    "            df.to_csv(output_filepath, index=False, header=False, quoting=csv.QUOTE_NONE, escapechar=' ')\n",
    "            print(f\"Converted {input_filepath} to {output_filepath}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error converting {input_filepath}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*csv to vtk for spatial plots*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully wrote C:/Users/Giannis/Desktop/neural_agent_models_data/vtk_outputs/vtk_outputs(250x250)/vtk_outputs(PINN 72-100)\\timestep_72.vtk\n",
      "Successfully wrote C:/Users/Giannis/Desktop/neural_agent_models_data/vtk_outputs/vtk_outputs(250x250)/vtk_outputs(PINN 72-100)\\timestep_73.vtk\n",
      "Successfully wrote C:/Users/Giannis/Desktop/neural_agent_models_data/vtk_outputs/vtk_outputs(250x250)/vtk_outputs(PINN 72-100)\\timestep_74.vtk\n",
      "Successfully wrote C:/Users/Giannis/Desktop/neural_agent_models_data/vtk_outputs/vtk_outputs(250x250)/vtk_outputs(PINN 72-100)\\timestep_75.vtk\n",
      "Successfully wrote C:/Users/Giannis/Desktop/neural_agent_models_data/vtk_outputs/vtk_outputs(250x250)/vtk_outputs(PINN 72-100)\\timestep_76.vtk\n",
      "Successfully wrote C:/Users/Giannis/Desktop/neural_agent_models_data/vtk_outputs/vtk_outputs(250x250)/vtk_outputs(PINN 72-100)\\timestep_77.vtk\n",
      "Successfully wrote C:/Users/Giannis/Desktop/neural_agent_models_data/vtk_outputs/vtk_outputs(250x250)/vtk_outputs(PINN 72-100)\\timestep_78.vtk\n",
      "Successfully wrote C:/Users/Giannis/Desktop/neural_agent_models_data/vtk_outputs/vtk_outputs(250x250)/vtk_outputs(PINN 72-100)\\timestep_79.vtk\n",
      "Successfully wrote C:/Users/Giannis/Desktop/neural_agent_models_data/vtk_outputs/vtk_outputs(250x250)/vtk_outputs(PINN 72-100)\\timestep_80.vtk\n",
      "Successfully wrote C:/Users/Giannis/Desktop/neural_agent_models_data/vtk_outputs/vtk_outputs(250x250)/vtk_outputs(PINN 72-100)\\timestep_81.vtk\n",
      "Successfully wrote C:/Users/Giannis/Desktop/neural_agent_models_data/vtk_outputs/vtk_outputs(250x250)/vtk_outputs(PINN 72-100)\\timestep_82.vtk\n",
      "Successfully wrote C:/Users/Giannis/Desktop/neural_agent_models_data/vtk_outputs/vtk_outputs(250x250)/vtk_outputs(PINN 72-100)\\timestep_83.vtk\n",
      "Successfully wrote C:/Users/Giannis/Desktop/neural_agent_models_data/vtk_outputs/vtk_outputs(250x250)/vtk_outputs(PINN 72-100)\\timestep_84.vtk\n",
      "Successfully wrote C:/Users/Giannis/Desktop/neural_agent_models_data/vtk_outputs/vtk_outputs(250x250)/vtk_outputs(PINN 72-100)\\timestep_85.vtk\n",
      "Successfully wrote C:/Users/Giannis/Desktop/neural_agent_models_data/vtk_outputs/vtk_outputs(250x250)/vtk_outputs(PINN 72-100)\\timestep_86.vtk\n",
      "Successfully wrote C:/Users/Giannis/Desktop/neural_agent_models_data/vtk_outputs/vtk_outputs(250x250)/vtk_outputs(PINN 72-100)\\timestep_87.vtk\n",
      "Successfully wrote C:/Users/Giannis/Desktop/neural_agent_models_data/vtk_outputs/vtk_outputs(250x250)/vtk_outputs(PINN 72-100)\\timestep_88.vtk\n",
      "Successfully wrote C:/Users/Giannis/Desktop/neural_agent_models_data/vtk_outputs/vtk_outputs(250x250)/vtk_outputs(PINN 72-100)\\timestep_89.vtk\n",
      "Successfully wrote C:/Users/Giannis/Desktop/neural_agent_models_data/vtk_outputs/vtk_outputs(250x250)/vtk_outputs(PINN 72-100)\\timestep_90.vtk\n",
      "Successfully wrote C:/Users/Giannis/Desktop/neural_agent_models_data/vtk_outputs/vtk_outputs(250x250)/vtk_outputs(PINN 72-100)\\timestep_91.vtk\n",
      "Successfully wrote C:/Users/Giannis/Desktop/neural_agent_models_data/vtk_outputs/vtk_outputs(250x250)/vtk_outputs(PINN 72-100)\\timestep_92.vtk\n",
      "Successfully wrote C:/Users/Giannis/Desktop/neural_agent_models_data/vtk_outputs/vtk_outputs(250x250)/vtk_outputs(PINN 72-100)\\timestep_93.vtk\n",
      "Successfully wrote C:/Users/Giannis/Desktop/neural_agent_models_data/vtk_outputs/vtk_outputs(250x250)/vtk_outputs(PINN 72-100)\\timestep_94.vtk\n",
      "Successfully wrote C:/Users/Giannis/Desktop/neural_agent_models_data/vtk_outputs/vtk_outputs(250x250)/vtk_outputs(PINN 72-100)\\timestep_95.vtk\n",
      "Successfully wrote C:/Users/Giannis/Desktop/neural_agent_models_data/vtk_outputs/vtk_outputs(250x250)/vtk_outputs(PINN 72-100)\\timestep_96.vtk\n",
      "Successfully wrote C:/Users/Giannis/Desktop/neural_agent_models_data/vtk_outputs/vtk_outputs(250x250)/vtk_outputs(PINN 72-100)\\timestep_97.vtk\n",
      "Successfully wrote C:/Users/Giannis/Desktop/neural_agent_models_data/vtk_outputs/vtk_outputs(250x250)/vtk_outputs(PINN 72-100)\\timestep_98.vtk\n",
      "Successfully wrote C:/Users/Giannis/Desktop/neural_agent_models_data/vtk_outputs/vtk_outputs(250x250)/vtk_outputs(PINN 72-100)\\timestep_99.vtk\n",
      "Successfully wrote C:/Users/Giannis/Desktop/neural_agent_models_data/vtk_outputs/vtk_outputs(250x250)/vtk_outputs(PINN 72-100)\\timestep_100.vtk\n"
     ]
    }
   ],
   "source": [
    "def csv_to_vtk_per_timestep(csv_file, output_dir):\n",
    "    try:\n",
    "        df = pd.read_csv(csv_file)\n",
    "\n",
    "        required_columns = ['timestep', 'X', 'Y']\n",
    "        if not all(column in df.columns for column in required_columns):\n",
    "            raise ValueError(f\"CSV file must contain columns: {', '.join(required_columns)}\")\n",
    "\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "\n",
    "        timesteps = df['timestep'].unique()\n",
    "        feature_names = [col for col in df.columns if col not in ['timestep', 'X', 'Y']]\n",
    "\n",
    "        for timestep in timesteps:\n",
    "            timestep_df = df[df['timestep'] == timestep]\n",
    "\n",
    "            # Create VTK StructuredPoints object\n",
    "            structured_points = vtk.vtkStructuredPoints()\n",
    "            structured_points.SetDimensions(250, 250, 1)  # adjust\n",
    "            structured_points.SetSpacing(1, 1, 1)\n",
    "            structured_points.SetOrigin(0, 0, 0)\n",
    "\n",
    "            # Add point data\n",
    "            point_data = structured_points.GetPointData()\n",
    "            for feature in feature_names:\n",
    "                feature_array = vtk.vtkFloatArray()\n",
    "                feature_array.SetName(feature)\n",
    "                feature_array.SetNumberOfComponents(1)\n",
    "                feature_array.SetNumberOfTuples(250 * 250)  # adjust\n",
    "\n",
    "                for index, value in enumerate(timestep_df[feature]):\n",
    "                    feature_array.SetValue(index, value)\n",
    "\n",
    "                point_data.AddArray(feature_array)\n",
    "\n",
    "            # Write the data to a VTK file\n",
    "            vtk_file_path = os.path.join(output_dir, f\"timestep_{timestep}.vtk\")\n",
    "            writer = vtk.vtkStructuredPointsWriter()\n",
    "            writer.SetFileName(vtk_file_path)\n",
    "            writer.SetInputData(structured_points)\n",
    "            writer.Write()\n",
    "            print(f\"Successfully wrote {vtk_file_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "csv_file_path = \"C:/Users/Giannis/Desktop/neural_agent_models_data/predictions/PINN(250x250)(72-100).csv\"\n",
    "output_dir = \"C:/Users/Giannis/Desktop/neural_agent_models_data/vtk_outputs/vtk_outputs(250x250)/vtk_outputs(PINN 72-100)\"\n",
    "csv_to_vtk_per_timestep(csv_file_path, output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Merge data from different runs of different train/test splits*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully wrote filtered data to C:/Users/Giannis/Documents/neural-agent-models-main/data/filtered_data.csv\n"
     ]
    }
   ],
   "source": [
    "def filter_timesteps(csv_file, output_file, max_timestep=10):\n",
    "    try:\n",
    "        # Read the CSV file\n",
    "        df = pd.read_csv(csv_file)\n",
    "\n",
    "        # Filter out rows with timestep >= max_timestep\n",
    "        filtered_df = df[df['timestep'] < max_timestep]\n",
    "\n",
    "        # Save the filtered DataFrame to a new CSV file\n",
    "        filtered_df.to_csv(output_file, index=False)\n",
    "        print(f\"Successfully wrote filtered data to {output_file}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "csv_file_path = \"C:/Users/Giannis/Desktop/neural_agent_models_data/predictions/PINN(250x250)(72-89hrs).csv\"\n",
    "output_file_path = \"C:/Users/Giannis/Documents/neural-agent-models-main/data/filtered_data.csv\"\n",
    "filter_timesteps(csv_file_path, output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully wrote merged data to C:/Users/Giannis/Desktop/neural_agent_models_data/predictions/PINN(250x250)(72-100).csv\n"
     ]
    }
   ],
   "source": [
    "def merge_and_rename_timesteps(filtered_file, new_file, output_file):\n",
    "\n",
    "    try:\n",
    "    \n",
    "        df_filtered = pd.read_csv(filtered_file)\n",
    "        df_new = pd.read_csv(new_file)\n",
    "\n",
    "        \n",
    "        df_filtered['timestep'] = df_filtered['timestep'] + 72\n",
    "        df_new['timestep'] = df_new['timestep'] + 82\n",
    "\n",
    "        merged_df = pd.concat([df_filtered, df_new], ignore_index=True)\n",
    "\n",
    "      \n",
    "        merged_df.to_csv(output_file, index=False)\n",
    "        print(f\"Successfully wrote merged data to {output_file}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "filtered_file_path = \"C:/Users/Giannis/Documents/neural-agent-models-main/data/filtered_data.csv\"\n",
    "new_file_path = \"C:/Users/Giannis/Desktop/neural_agent_models_data/predictions/PINN(250x250)(82-100hrs).csv\"\n",
    "output_file_path = \"C:/Users/Giannis/Desktop/neural_agent_models_data/predictions/PINN(250x250)(72-100).csv\"\n",
    "merge_and_rename_timesteps(filtered_file_path, new_file_path, output_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
