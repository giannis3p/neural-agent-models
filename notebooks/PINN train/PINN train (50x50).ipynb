{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PINN implementation for 50x50 grid using deepxde**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow==2.10.0\n",
    "pip install matplotlib==3.7.4\n",
    "pip install scipy==1.10.1\n",
    "pip install pandas==2.0.3\n",
    "pip install deepxde==1.10.1\n",
    "pip install numpy==1.24.3\n",
    "pip install scikit-learn==1.3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import solve_ivp\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import deepxde as dde\n",
    "# Set default floating-point type\n",
    "tf.keras.backend.set_floatx('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seeds for reproducibility\n",
    "seed_value = 42\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "\n",
    "# Configure TensorFlow for deterministic behavior\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
    "\n",
    "# Control threading for reproducibility\n",
    "tf.config.threading.set_inter_op_parallelism_threads(1)\n",
    "tf.config.threading.set_intra_op_parallelism_threads(1)\n",
    "\n",
    "# Ensure GPU determinism\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "# Define He initializer\n",
    "initializer = tf.keras.initializers.HeNormal(seed=seed_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Same as with the LSTM models we construct arrays*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mcsteps  xCOM  yCOM               il8   il1   il6  il10   tnf   tgf\n",
      "0        0    18    35   [3.7056725e-07]  [0.]  [0.]  [0.]  [0.]  [0.]\n",
      "1        0    10    26    [6.053245e-14]  [0.]  [0.]  [0.]  [0.]  [0.]\n",
      "2        0    42    39  [1.07021676e-10]  [0.]  [0.]  [0.]  [0.]  [0.]\n",
      "3        0    42    11   [1.0511393e-10]  [0.]  [0.]  [0.]  [0.]  [0.]\n",
      "4        0    31    31   [2.5496664e-12]  [0.]  [0.]  [0.]  [0.]  [0.]\n",
      "       time  xCOM  yCOM               il8              il1              il6  \\\n",
      "0         0    18    35   [3.7056725e-07]             [0.]             [0.]   \n",
      "1         0    10    26    [6.053245e-14]             [0.]             [0.]   \n",
      "2         0    42    39  [1.07021676e-10]             [0.]             [0.]   \n",
      "3         0    42    11   [1.0511393e-10]             [0.]             [0.]   \n",
      "4         0    31    31   [2.5496664e-12]             [0.]             [0.]   \n",
      "...     ...   ...   ...               ...              ...              ...   \n",
      "15296   100    15    14  [1.15002695e-05]   [2.386459e-07]   [2.259021e-17]   \n",
      "15297   100    42    18   [3.2883138e-09]  [1.2279276e-09]  [6.5437716e-17]   \n",
      "15298   100    32    20   [1.3584007e-06]  [2.6746378e-07]  [2.7199043e-11]   \n",
      "15299   100    43    34   [9.1763343e-07]  [2.0156235e-10]  [1.0609837e-10]   \n",
      "15300   100    25    24   [1.3072353e-05]  [1.1181754e-09]  [2.2057786e-15]   \n",
      "\n",
      "                  il10              tnf              tgf  \n",
      "0                 [0.]             [0.]             [0.]  \n",
      "1                 [0.]             [0.]             [0.]  \n",
      "2                 [0.]             [0.]             [0.]  \n",
      "3                 [0.]             [0.]             [0.]  \n",
      "4                 [0.]             [0.]             [0.]  \n",
      "...                ...              ...              ...  \n",
      "15296  [1.1952197e-22]  [3.5314193e-07]  [2.0131348e-07]  \n",
      "15297   [1.829023e-21]   [9.195441e-13]  [8.5320444e-08]  \n",
      "15298  [1.4739978e-13]  [3.9898168e-07]  [1.3509495e-08]  \n",
      "15299   [5.953796e-13]   [9.758741e-14]   [4.894749e-07]  \n",
      "15300  [6.4972045e-20]   [9.182094e-13]  [5.2418225e-09]  \n",
      "\n",
      "[15301 rows x 9 columns]\n",
      "Smallest values for each cytokine:\n",
      "il8     [0.]\n",
      "il1     [0.]\n",
      "il6     [0.]\n",
      "il10    [0.]\n",
      "tnf     [0.]\n",
      "tgf     [0.]\n",
      "dtype: object\n",
      "\n",
      "Largest values for each cytokine:\n",
      "il8     [9.998227e-11]\n",
      "il1     [9.999076e-32]\n",
      "il6     [9.999909e-13]\n",
      "il10          [9.e-44]\n",
      "tnf     [9.998967e-13]\n",
      "tgf     [9.997706e-15]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "sorted_concatenated_csv = \"C:/Users/Ioannis/Documents/neural-agent-models/data/simulation data/50x50.csv\"\n",
    "data = pd.read_csv(sorted_concatenated_csv)\n",
    "#data.drop(columns=['zCOM'], inplace=True)\n",
    "print(data.head())\n",
    "data['time'] = (data['mcsteps'] / 10000).astype(int)\n",
    "data = data[['time'] + [col for col in data.columns if col != 'time']]\n",
    "data.drop(columns=['mcsteps'], inplace=True)\n",
    "print(data)\n",
    "cytokine_columns = ['il8', 'il1', 'il6', 'il10', 'tnf', 'tgf']\n",
    "smallest_values = data[cytokine_columns].min()\n",
    "largest_values = data[cytokine_columns].max()\n",
    "\n",
    "print(\"Smallest values for each cytokine:\")\n",
    "print(smallest_values)\n",
    "print(\"\\nLargest values for each cytokine:\")\n",
    "print(largest_values)\n",
    "#def replace_negative_with_zero(data):\n",
    " #   num_negative_values = (data < 0).sum().sum()\n",
    "  #  data[data < 0] = 0\n",
    "\n",
    "   # return num_negative_values\n",
    "\n",
    "#cytokine_columns = ['il8', 'il1', 'il6', 'il10', 'tnf', 'tgf']\n",
    "\n",
    "#for col in cytokine_columns:\n",
    " #   num_negatives = replace_negative_with_zero(data[col])\n",
    "  #  print(f\"Number of negative values replaced with 0 in '{col}': {num_negatives}\")\n",
    "\n",
    "# define cytokines\n",
    "cytokines = ['il8', 'il1', 'il6', 'il10', 'tnf', 'tgf']\n",
    "\n",
    "# Remove brackets and convert to float\n",
    "for col in cytokines:\n",
    "    data[col] = data[col].str.strip('[]').astype(float)\n",
    "\n",
    "# get unique time values\n",
    "unique_time = data['time'].unique()\n",
    "\n",
    "arrays = {}\n",
    "\n",
    "# iterate over unique time values\n",
    "for time in unique_time:\n",
    "    # filter data for current value of time\n",
    "    data_time = data[data['time'] == time]\n",
    "    \n",
    "    # initialize 50x50x6 array for current value of time\n",
    "    array = np.zeros((50, 50, len(cytokines)))\n",
    "    \n",
    "    # get X and Y coordinates\n",
    "    x = data_time['xCOM'].astype(int)\n",
    "    y = data_time['yCOM'].astype(int)\n",
    "    \n",
    "    # get cytokine concentrations\n",
    "    concentrations = data_time[['il8', 'il1', 'il6', 'il10', 'tnf', 'tgf']].values\n",
    "    \n",
    "    # assign cytokine concentrations to corresponding position in array\n",
    "    array[x, y, :] = concentrations\n",
    "    \n",
    "    # store array for current value of time\n",
    "    arrays[time] = array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*creating input/output pairs for the PINN*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(91, 10, 50, 50, 6)\n",
      "(91, 50, 50, 6)\n"
     ]
    }
   ],
   "source": [
    "sequence_length = 10\n",
    "input_sequences = []\n",
    "output_values = []\n",
    "\n",
    "# convert dictionary values to a list of arrays\n",
    "arrays_list = [arrays[key] for key in sorted(arrays.keys())]\n",
    "\n",
    "# convert 'arrays' list to numpy array\n",
    "arrays_np = np.array(arrays_list)\n",
    "\n",
    "for i in range(len(arrays_np) - sequence_length):\n",
    "    input_seq = arrays_np[i:i+sequence_length]  # input sequence of arrays\n",
    "    output_val = arrays_np[i+sequence_length]   # array at next time step\n",
    "    \n",
    "    input_sequences.append(input_seq)\n",
    "    output_values.append(output_val)\n",
    "\n",
    "# convert lists to numpy arrays\n",
    "input_sequences = np.array(input_sequences)\n",
    "output_values = np.array(output_values)\n",
    "\n",
    "print(input_sequences.shape)\n",
    "print(output_values.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*In the next few cells we extract cellposition from .vtk files which is essential to compute the pde residual in the PINN*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cell type at (31, 31) at timestep 0 is 10\n"
     ]
    }
   ],
   "source": [
    "def read_vtk_file(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    dimensions = None\n",
    "    cell_type_data_start = None\n",
    "    for i, line in enumerate(lines):\n",
    "        if line.startswith(\"DIMENSIONS\"):\n",
    "            dimensions = list(map(int, line.split()[1:]))\n",
    "        elif line.startswith(\"CellType\"):\n",
    "            cell_type_data_start = i + 1\n",
    "            break\n",
    "    \n",
    "    if dimensions is None or cell_type_data_start is None:\n",
    "        raise ValueError(\"Invalid VTK file format\")\n",
    "    \n",
    "    grid_data = []\n",
    "    data_lines = lines[cell_type_data_start:]\n",
    "    for line in data_lines:\n",
    "        if line.strip() and not line.startswith(\"FIELD\"):\n",
    "            try:\n",
    "                grid_data.extend(map(int, line.split()))\n",
    "                if len(grid_data) >= dimensions[0] * dimensions[1]:\n",
    "                    break\n",
    "            except ValueError:\n",
    "                continue  # Skip lines that can't be converted to int\n",
    "    \n",
    "    expected_size = dimensions[0] * dimensions[1]\n",
    "    if len(grid_data) != expected_size:\n",
    "        raise ValueError(f\"Data size {len(grid_data)} does not match expected size {expected_size}\")\n",
    "\n",
    "    grid_data = np.array(grid_data[:expected_size]).reshape((dimensions[0], dimensions[1], 1))\n",
    "    return grid_data\n",
    "\n",
    "def process_vtk_files(directory):\n",
    "    vtk_arrays = []\n",
    "    for filename in sorted(os.listdir(directory)):\n",
    "        if filename.endswith(\".vtk\"):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            grid_data = read_vtk_file(filepath)\n",
    "            vtk_arrays.append(grid_data)\n",
    "    return vtk_arrays\n",
    "\n",
    "directory = 'C:/Users/Ioannis/Documents/neural-agent-models/data/LatticeData/LatticeData(50x50)'\n",
    "vtk_arrays = process_vtk_files(directory)\n",
    "\n",
    "# Check the 3D array for a specific coordinate and timestep\n",
    "timestep = 0  # Timestep index\n",
    "x, y = 31, 31  # Coordinates to check\n",
    "cell_type = vtk_arrays[timestep][x, y, 0]\n",
    "print(f\"The cell type at ({x}, {y}) at timestep {timestep} is {cell_type}\")\n",
    "\n",
    "# The vtk_arrays will contain all the 3D arrays for each timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\n"
     ]
    }
   ],
   "source": [
    "print(vtk_arrays[0][31,31])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestep 0:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 1\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 0\n",
      "  cellpresentm2: 0\n",
      "Timestep 1:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 1\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 1\n",
      "  cellpresentm2: 0\n",
      "Timestep 2:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 1\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 0\n",
      "  cellpresentm2: 1\n",
      "Timestep 3:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 1\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 1\n",
      "  cellpresentm2: 0\n",
      "Timestep 4:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 1\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 1\n",
      "  cellpresentm2: 1\n",
      "Timestep 5:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 1\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 1\n",
      "  cellpresentm2: 1\n",
      "Timestep 6:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 1\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 1\n",
      "  cellpresentm2: 1\n",
      "Timestep 7:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 1\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 1\n",
      "  cellpresentm2: 1\n",
      "Timestep 8:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 1\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 1\n",
      "  cellpresentm2: 1\n",
      "Timestep 9:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 1\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 1\n",
      "  cellpresentm2: 1\n",
      "Timestep 10:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 1\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 1\n",
      "  cellpresentm2: 1\n",
      "Timestep 11:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 1\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 1\n",
      "  cellpresentm2: 1\n",
      "Timestep 12:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 1\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 1\n",
      "  cellpresentm2: 1\n",
      "Timestep 13:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 1\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 1\n",
      "  cellpresentm2: 1\n",
      "Timestep 14:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 1\n",
      "  cellpresentm2: 1\n",
      "Timestep 15:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 1\n",
      "  cellpresentm2: 1\n",
      "Timestep 16:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 0\n",
      "  cellpresentm2: 1\n",
      "Timestep 17:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 1\n",
      "  cellpresentm2: 1\n",
      "Timestep 18:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 0\n",
      "  cellpresentm2: 1\n",
      "Timestep 19:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 1\n",
      "  cellpresentm2: 1\n",
      "Timestep 20:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 1\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 0\n",
      "  cellpresentm2: 1\n",
      "Timestep 21:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 1\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 1\n",
      "  cellpresentm2: 1\n",
      "Timestep 22:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 1\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 1\n",
      "  cellpresentm2: 1\n",
      "Timestep 23:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 1\n",
      "  cellpresentm2: 1\n",
      "Timestep 24:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 1\n",
      "  cellpresentm2: 1\n",
      "Timestep 25:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 0\n",
      "  cellpresentm2: 1\n",
      "Timestep 26:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 1\n",
      "  cellpresentm2: 1\n",
      "Timestep 27:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 1\n",
      "  cellpresentm2: 1\n",
      "Timestep 28:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 0\n",
      "  cellpresentm2: 1\n",
      "Timestep 29:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 0\n",
      "  cellpresentm1: 0\n",
      "  cellpresentm2: 1\n",
      "Timestep 30:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 0\n",
      "  cellpresentm2: 1\n",
      "Timestep 31:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 1\n",
      "  cellpresentm2: 1\n",
      "Timestep 32:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 0\n",
      "  cellpresentm2: 1\n",
      "Timestep 33:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 0\n",
      "  cellpresentm2: 1\n",
      "Timestep 34:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 0\n",
      "  cellpresentm2: 1\n",
      "Timestep 35:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 0\n",
      "  cellpresentm2: 1\n",
      "Timestep 36:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 1\n",
      "  cellpresentm2: 1\n",
      "Timestep 37:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 0\n",
      "  cellpresentm2: 1\n",
      "Timestep 38:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 0\n",
      "  cellpresentm2: 1\n",
      "Timestep 39:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 1\n",
      "  cellpresentm2: 1\n",
      "Timestep 40:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 1\n",
      "  cellpresentm2: 1\n",
      "Timestep 41:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 1\n",
      "  cellpresentm2: 1\n",
      "Timestep 42:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 1\n",
      "  cellpresentm2: 1\n",
      "Timestep 43:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 0\n",
      "  cellpresentm2: 1\n",
      "Timestep 44:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 1\n",
      "  cellpresentm2: 1\n",
      "Timestep 45:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 0\n",
      "  cellpresentm2: 1\n",
      "Timestep 46:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 1\n",
      "  cellpresentm2: 1\n",
      "Timestep 47:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 0\n",
      "  cellpresentm2: 1\n",
      "Timestep 48:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 0\n",
      "  cellpresentm1: 0\n",
      "  cellpresentm2: 1\n",
      "Timestep 49:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 0\n",
      "  cellpresentm1: 0\n",
      "  cellpresentm2: 1\n",
      "Timestep 50:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 1\n",
      "  cellpresentm2: 1\n",
      "Timestep 51:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 1\n",
      "  cellpresentm2: 1\n",
      "Timestep 52:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 1\n",
      "  cellpresentm2: 1\n",
      "Timestep 53:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 1\n",
      "  cellpresentm2: 1\n",
      "Timestep 54:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 1\n",
      "  cellpresentm2: 1\n",
      "Timestep 55:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 0\n",
      "  cellpresentm2: 1\n",
      "Timestep 56:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 1\n",
      "  cellpresentm2: 1\n",
      "Timestep 57:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 0\n",
      "  cellpresentm2: 1\n",
      "Timestep 58:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 0\n",
      "  cellpresentm2: 1\n",
      "Timestep 59:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 0\n",
      "  cellpresentm2: 1\n",
      "Timestep 60:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 1\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 0\n",
      "  cellpresentm2: 1\n",
      "Timestep 61:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 1\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 1\n",
      "  cellpresentm2: 1\n",
      "Timestep 62:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 1\n",
      "  cellpresentm2: 1\n",
      "Timestep 63:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 0\n",
      "  cellpresentm2: 1\n",
      "Timestep 64:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 1\n",
      "  cellpresentm2: 1\n",
      "Timestep 65:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 1\n",
      "  cellpresentm2: 1\n",
      "Timestep 66:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 0\n",
      "  cellpresentm2: 1\n",
      "Timestep 67:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 0\n",
      "  cellpresentm1: 0\n",
      "  cellpresentm2: 1\n",
      "Timestep 68:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 0\n",
      "  cellpresentm1: 1\n",
      "  cellpresentm2: 1\n",
      "Timestep 69:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 0\n",
      "  cellpresentm1: 0\n",
      "  cellpresentm2: 1\n",
      "Timestep 70:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 1\n",
      "  cellpresentna: 0\n",
      "  cellpresentm1: 0\n",
      "  cellpresentm2: 1\n",
      "Timestep 71:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 1\n",
      "  cellpresentna: 0\n",
      "  cellpresentm1: 0\n",
      "  cellpresentm2: 1\n",
      "Timestep 72:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 0\n",
      "  cellpresentm2: 1\n",
      "Timestep 73:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 1\n",
      "  cellpresentm2: 1\n",
      "Timestep 74:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 0\n",
      "  cellpresentm2: 1\n",
      "Timestep 75:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 1\n",
      "  cellpresentm2: 1\n",
      "Timestep 76:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 0\n",
      "  cellpresentm2: 1\n",
      "Timestep 77:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 1\n",
      "  cellpresentm2: 1\n",
      "Timestep 78:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 0\n",
      "  cellpresentm2: 1\n",
      "Timestep 79:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 0\n",
      "  cellpresentm2: 1\n",
      "Timestep 80:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 1\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 0\n",
      "  cellpresentm2: 1\n",
      "Timestep 81:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 1\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 1\n",
      "  cellpresentm2: 1\n",
      "Timestep 82:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 1\n",
      "  cellpresentna: 0\n",
      "  cellpresentm1: 0\n",
      "  cellpresentm2: 1\n",
      "Timestep 83:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 0\n",
      "  cellpresentm1: 1\n",
      "  cellpresentm2: 1\n",
      "Timestep 84:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 0\n",
      "  cellpresentm1: 0\n",
      "  cellpresentm2: 1\n",
      "Timestep 85:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 0\n",
      "  cellpresentm1: 0\n",
      "  cellpresentm2: 1\n",
      "Timestep 86:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 0\n",
      "  cellpresentm1: 0\n",
      "  cellpresentm2: 1\n",
      "Timestep 87:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 0\n",
      "  cellpresentm1: 1\n",
      "  cellpresentm2: 1\n",
      "Timestep 88:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 0\n",
      "  cellpresentm1: 0\n",
      "  cellpresentm2: 1\n",
      "Timestep 89:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 0\n",
      "  cellpresentm1: 0\n",
      "  cellpresentm2: 1\n",
      "Timestep 90:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 0\n",
      "  cellpresentm2: 1\n",
      "Timestep 91:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 0\n",
      "  cellpresentm2: 1\n",
      "Timestep 92:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 1\n",
      "  cellpresentm2: 1\n",
      "Timestep 93:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 1\n",
      "  cellpresentm1: 1\n",
      "  cellpresentm2: 1\n",
      "Timestep 94:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 0\n",
      "  cellpresentm1: 1\n",
      "  cellpresentm2: 1\n",
      "Timestep 95:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 0\n",
      "  cellpresentm1: 0\n",
      "  cellpresentm2: 1\n",
      "Timestep 96:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 0\n",
      "  cellpresentm1: 0\n",
      "  cellpresentm2: 1\n",
      "Timestep 97:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 0\n",
      "  cellpresentm1: 0\n",
      "  cellpresentm2: 1\n",
      "Timestep 98:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 0\n",
      "  cellpresentm1: 0\n",
      "  cellpresentm2: 1\n",
      "Timestep 99:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 0\n",
      "  cellpresentna: 0\n",
      "  cellpresentm1: 0\n",
      "  cellpresentm2: 1\n",
      "Timestep 100:\n",
      "  cellpresente: 1\n",
      "  cellpresentndn: 1\n",
      "  cellpresentna: 0\n",
      "  cellpresentm1: 1\n",
      "  cellpresentm2: 1\n"
     ]
    }
   ],
   "source": [
    "def check_cell_presence(vtk_arrays, start_idx, end_idx):\n",
    "    cellpresente = []\n",
    "    cellpresentndn = []\n",
    "    cellpresentna = []\n",
    "    cellpresentm1 = []\n",
    "    cellpresentm2 = []\n",
    "\n",
    "    for i in range(start_idx, end_idx + 1):\n",
    "        array = vtk_arrays[i].reshape(50, 50)\n",
    "        cellpresente.append(1 if np.any(array == 1) else 0)\n",
    "        cellpresentndn.append(1 if np.any(array == 2) else 0)\n",
    "        cellpresentna.append(1 if np.any(array == 5) else 0)\n",
    "        cellpresentm1.append(1 if np.any(array == 8) else 0)\n",
    "        cellpresentm2.append(1 if np.any(array == 9) else 0)\n",
    "    return cellpresente, cellpresentndn, cellpresentna, cellpresentm1, cellpresentm2\n",
    "\n",
    "# Adjust the range to 0-100\n",
    "cellpresente, cellpresentndn, cellpresentna, cellpresentm1, cellpresentm2 = check_cell_presence(vtk_arrays, 0, 100)\n",
    "\n",
    "# Output the results\n",
    "for t in range(0, 101):\n",
    "    idx = t  # Index directly corresponds to the timestep\n",
    "    print(f\"Timestep {t}:\")\n",
    "    print(f\"  cellpresente: {cellpresente[idx]}\")\n",
    "    print(f\"  cellpresentndn: {cellpresentndn[idx]}\")\n",
    "    print(f\"  cellpresentna: {cellpresentna[idx]}\")\n",
    "    print(f\"  cellpresentm1: {cellpresentm1[idx]}\")\n",
    "    print(f\"  cellpresentm2: {cellpresentm2[idx]}\")\n",
    "\n",
    "output_dir = 'C:/Users/Ioannis/Documents/neural-agent-models/data/PINN/Results'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "results = np.column_stack((range(0, 101), cellpresente, cellpresentndn, cellpresentna, cellpresentm1, cellpresentm2))\n",
    "np.savetxt(os.path.join(output_dir, 'cell_presence_results.csv'), results, delimiter=',', header='Timestep,cellpresente,cellpresentndn,cellpresentna,cellpresentm1,cellpresentm2', comments='', fmt='%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Parameters for our PINN to solve the PDE*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cellpresente: (91,)\n",
      "cellpresentndn: (91,)\n",
      "cellpresentna: (91,)\n",
      "cellpresentm1: (91,)\n",
      "cellpresentm2: (91,)\n",
      "s1: Tensor(\"stack:0\", shape=(6, 91), dtype=float32)\n",
      "s2: Tensor(\"stack_1:0\", shape=(6, 91), dtype=float32)\n",
      "e: Tensor(\"stack_2:0\", shape=(6, 91), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Simulation parameters\n",
    "nx = 50\n",
    "true_size = 5\n",
    "s_mcs = 60.0\n",
    "h_mcs = 1 / 60.0\n",
    "lineconv = true_size / nx\n",
    "areaconv = true_size**2 / nx**2\n",
    "volumeconv = (true_size**2 * 1) / (nx**2 * 1)\n",
    "\n",
    "# Parameters for each cytokine\n",
    "Dil8 = 2.09e-6 * s_mcs / areaconv\n",
    "muil8 = 0.2 * h_mcs\n",
    "keil8 = 234e-5 * volumeconv * h_mcs\n",
    "kndnil8 = 1.46e-5 * volumeconv * h_mcs\n",
    "thetanail8 = 3.024e-5 * volumeconv * h_mcs\n",
    "\n",
    "Dil1 = 3e-7 * s_mcs / areaconv\n",
    "muil1 = 0.6 * h_mcs\n",
    "knail1 = 225e-5 * volumeconv * h_mcs\n",
    "\n",
    "Dil6 = 8.49e-8 * s_mcs / areaconv\n",
    "muil6 = 0.5 * h_mcs\n",
    "km1il6 = 250e-5 * volumeconv * h_mcs\n",
    "\n",
    "Dil10 = 1.45e-8 * s_mcs / areaconv\n",
    "muil10 = 0.5 * h_mcs\n",
    "km2il10 = 45e-5 * volumeconv * h_mcs\n",
    "\n",
    "Dtnf = 4.07e-9 * s_mcs / areaconv\n",
    "mutnf = 0.5 * 0.225 * h_mcs\n",
    "knatnf = 250e-5 * volumeconv * h_mcs\n",
    "km1tnf = 70e-5 * volumeconv * h_mcs\n",
    "\n",
    "Dtgf = 2.6e-7 * s_mcs / areaconv\n",
    "mutgf = 0.5 * (1 / 25) * h_mcs\n",
    "km2tgf = 280e-5 * volumeconv * h_mcs\n",
    "\n",
    "cellpresente = np.array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
    "cellpresentndn = np.array([1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1])\n",
    "cellpresentna = np.array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0])\n",
    "cellpresentm1 = np.array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0])\n",
    "cellpresentm2 = np.array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
    "\n",
    "# Optionally, print the arrays to verify\n",
    "print(\"cellpresente:\", cellpresente.shape)\n",
    "print(\"cellpresentndn:\", cellpresentndn.shape)\n",
    "print(\"cellpresentna:\", cellpresentna.shape)\n",
    "print(\"cellpresentm1:\", cellpresentm1.shape)\n",
    "print(\"cellpresentm2:\", cellpresentm2.shape)\n",
    "\n",
    "# Convert the NumPy arrays to TensorFlow constants\n",
    "cellpresente_tf = tf.constant(cellpresente, dtype=tf.float32)\n",
    "cellpresentndn_tf = tf.constant(cellpresentndn, dtype=tf.float32)\n",
    "cellpresentna_tf = tf.constant(cellpresentna, dtype=tf.float32)\n",
    "cellpresentm1_tf = tf.constant(cellpresentm1, dtype=tf.float32)\n",
    "cellpresentm2_tf = tf.constant(cellpresentm2, dtype=tf.float32)\n",
    "\n",
    "# Define the parameters as TensorFlow constants\n",
    "keil8_tf = tf.constant(keil8, dtype=tf.float32)\n",
    "knail1_tf = tf.constant(knail1, dtype=tf.float32)\n",
    "km1il6_tf = tf.constant(km1il6, dtype=tf.float32)\n",
    "km2il10_tf = tf.constant(km2il10, dtype=tf.float32)\n",
    "knatnf_tf = tf.constant(knatnf, dtype=tf.float32)\n",
    "km2tgf_tf = tf.constant(km2tgf, dtype=tf.float32)\n",
    "kndnil8_tf = tf.constant(kndnil8, dtype=tf.float32)\n",
    "km1tnf_tf = tf.constant(km1tnf, dtype=tf.float32)\n",
    "thetanail8_tf = tf.constant(thetanail8, dtype=tf.float32)\n",
    "\n",
    "# diffusion degradation secretion endocytosis\n",
    "D = np.array([Dil8, Dil1, Dil6, Dil10, Dtnf, Dtgf])\n",
    "k = np.array([muil8, muil1, muil6, muil10, mutnf, mutgf])\n",
    "\n",
    "# Stack the parameters for secretion and endocytosis\n",
    "s1 = tf.stack([\n",
    "    keil8_tf * cellpresente_tf,\n",
    "    knail1_tf * cellpresentna_tf,\n",
    "    km1il6_tf * cellpresentm1_tf,\n",
    "    km2il10_tf * cellpresentm1_tf,\n",
    "    knatnf_tf * cellpresentna_tf,\n",
    "    km2tgf_tf * cellpresentm2_tf\n",
    "], axis=0)\n",
    "\n",
    "s2 = tf.stack([\n",
    "    kndnil8_tf * cellpresentndn_tf,\n",
    "    tf.zeros_like(cellpresentndn_tf, dtype=tf.float32),\n",
    "    tf.zeros_like(cellpresentndn_tf, dtype=tf.float32),\n",
    "    tf.zeros_like(cellpresentndn_tf, dtype=tf.float32),\n",
    "    km1tnf_tf * cellpresentm1_tf,\n",
    "    tf.zeros_like(cellpresentndn_tf, dtype=tf.float32)\n",
    "], axis=0)\n",
    "\n",
    "e = tf.stack([\n",
    "    thetanail8_tf * cellpresentna_tf,\n",
    "    tf.zeros_like(cellpresentndn_tf, dtype=tf.float32),\n",
    "    tf.zeros_like(cellpresentndn_tf, dtype=tf.float32),\n",
    "    tf.zeros_like(cellpresentndn_tf, dtype=tf.float32),\n",
    "    tf.zeros_like(cellpresentndn_tf, dtype=tf.float32),\n",
    "    tf.zeros_like(cellpresentndn_tf, dtype=tf.float32)\n",
    "], axis=0)\n",
    "\n",
    "print(\"s1:\", s1)\n",
    "print(\"s2:\", s2)\n",
    "print(\"e:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*PINN implementation using deepxde, this cell contains everything including the NN architecture, loss function, metrics, etc*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D: [1.254e-02 1.800e-03 5.094e-04 8.700e-05 2.442e-05 1.560e-03]\n",
      "k: [0.00333333 0.01       0.00833333 0.00833333 0.001875   0.00033333]\n",
      "s1: Tensor(\"stack:0\", shape=(6, 91), dtype=float32)\n",
      "s2: Tensor(\"stack_1:0\", shape=(6, 91), dtype=float32)\n",
      "e: Tensor(\"stack_2:0\", shape=(6, 91), dtype=float32)\n",
      "X_train shape: (63, 150000), y_train shape: (63, 15000)\n",
      "X_val shape: (9, 150000), y_val shape: (9, 15000)\n",
      "X_test shape: (19, 150000), y_test shape: (19, 15000)\n",
      "Custom data set defined\n",
      "Compiling model...\n",
      "Building feed-forward neural network...\n",
      "'build' took 0.031577 s\n",
      "\n",
      "'compile' took 0.163956 s\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ioannis\\AppData\\Roaming\\Python\\Python38\\site-packages\\deepxde\\nn\\tensorflow_compat_v1\\fnn.py:116: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  return tf.layers.dense(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "\n",
      "Step      Train loss    Test loss     Test metric   \n",
      "0         [3.63e-13]    [6.38e-13]    [6.38e-13]    \n",
      "Starting training...\n",
      "1000      [2.38e-14]    [5.41e-14]    [5.41e-14]    \n",
      "Saved training data at epoch 1000\n",
      "2000      [2.38e-14]    [5.41e-14]    [5.41e-14]    \n",
      "Saved training data at epoch 2000\n",
      "3000      [2.38e-14]    [5.41e-14]    [5.41e-14]    \n",
      "Saved training data at epoch 3000\n",
      "4000      [2.38e-14]    [5.41e-14]    [5.41e-14]    \n",
      "Saved training data at epoch 4000\n",
      "5000      [2.38e-14]    [5.41e-14]    [5.41e-14]    \n",
      "Saved training data at epoch 5000\n",
      "6000      [2.38e-14]    [5.41e-14]    [5.41e-14]    \n",
      "Saved training data at epoch 6000\n",
      "7000      [2.38e-14]    [5.41e-14]    [5.41e-14]    \n",
      "Saved training data at epoch 7000\n",
      "8000      [2.38e-14]    [5.41e-14]    [5.41e-14]    \n",
      "Saved training data at epoch 8000\n",
      "9000      [2.38e-14]    [5.41e-14]    [5.41e-14]    \n",
      "Saved training data at epoch 9000\n",
      "10000     [2.38e-14]    [5.41e-14]    [5.41e-14]    \n",
      "Saved training data at epoch 10000\n",
      "Training finished and data saved.\n",
      "\n",
      "Best model at step 2000:\n",
      "  train loss: 2.38e-14\n",
      "  test loss: 5.41e-14\n",
      "  test metric: [5.41e-14]\n",
      "\n",
      "'train' took 60.604867 s\n",
      "\n",
      "Mean Absolute Percentage Error (MAPE) on the test set: 10.671973560593134\n",
      "Mean Squared Error (MSE) on the test set: 8.136579498233757e-14\n",
      "Mean Absolute Error (MAE) on the test set: 2.5661385495230145e-08\n",
      "Mean Squared Logarithmic Error (MSLE) on the test set: 8.136438438121213e-14\n",
      "R-squared (RÂ²) on the test set: 0.8870115185809019\n",
      "Accuracy on the test set: 0.9262175438596492\n",
      "y_pred: (19, 15000)\n",
      "y_pred_flat: (19, 50, 50, 6)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"D:\", D)\n",
    "print(\"k:\", k)\n",
    "print(\"s1:\", s1)\n",
    "print(\"s2:\", s2)\n",
    "print(\"e:\", e)\n",
    "\n",
    "# Define the PDE\n",
    "def pde(x, y):\n",
    "    u = [y[:, i:i+1] for i in range(6)]\n",
    "    laplacian_u = [dde.grad.hessian(u[i], x, i=1, j=1) + dde.grad.hessian(u[i], x, i=2, j=2) for i in range(6)]\n",
    "    laplacian_u = tf.concat(laplacian_u, axis=1)\n",
    "    degradation = k * y\n",
    "\n",
    "    # Extract the time component from x\n",
    "    time_idx = tf.cast(tf.floor(x[:, 2]), tf.int32)\n",
    "\n",
    "    # Gather the appropriate values from s1, s2, and e based on time_idx\n",
    "    secretion_1 = tf.gather(tf.transpose(s1), time_idx)\n",
    "    secretion_2 = tf.gather(tf.transpose(s2), time_idx)\n",
    "    endocytosis = tf.gather(tf.transpose(e), time_idx) * y\n",
    "\n",
    "    return laplacian_u * D - degradation + secretion_1 + secretion_2 - endocytosis\n",
    "\n",
    "# Define the geometry and time domain\n",
    "geom = dde.geometry.Rectangle([0, 0], [50, 50])\n",
    "timedomain = dde.geometry.TimeDomain(0, 1)\n",
    "geomtime = dde.geometry.GeometryXTime(geom, timedomain)\n",
    "\n",
    "# Define the initial condition\n",
    "def initial_condition(x):\n",
    "    return np.zeros((x.shape[0], 6))\n",
    "\n",
    "# Define the Neumann boundary condition\n",
    "def neumann_boundary(x, on_boundary):\n",
    "    return on_boundary\n",
    "\n",
    "def neumann_bc(x, y, nx, ny):\n",
    "    grad = [dde.grad.jacobian(y, x, i=0, j=j) for j in range(3)]\n",
    "    return sum([g * n for g, n in zip(grad, [nx, ny])])\n",
    "\n",
    "# Initial and boundary conditions\n",
    "ic = dde.IC(geomtime, initial_condition, lambda _, on_initial: on_initial)\n",
    "bc = dde.NeumannBC(geomtime, neumann_bc, neumann_boundary)\n",
    "\n",
    "# Reshape input_sequences\n",
    "input_sequences_reshaped = input_sequences.reshape(input_sequences.shape[0], -1)\n",
    "\n",
    "# Flatten the output values\n",
    "output_values_reshaped = output_values.reshape(output_values.shape[0], -1)\n",
    "\n",
    "# Define train, validation, and test sizes\n",
    "train_size = int(0.7 * input_sequences_reshaped.shape[0])\n",
    "val_size = int(0.1 * input_sequences_reshaped.shape[0])\n",
    "test_size = input_sequences_reshaped.shape[0] - train_size - val_size\n",
    "\n",
    "# Split data\n",
    "X_train = input_sequences_reshaped[:train_size]\n",
    "X_val = input_sequences_reshaped[train_size:train_size + val_size]\n",
    "X_test = input_sequences_reshaped[train_size + val_size:]\n",
    "y_train = output_values_reshaped[:train_size]\n",
    "y_val = output_values_reshaped[train_size:train_size + val_size]\n",
    "y_test = output_values_reshaped[train_size + val_size:]\n",
    "\n",
    "# adjust for 2nd split\n",
    "#train_size = int(0.7 * input_sequences_reshaped.shape[0])\n",
    "#test_size = int(0.20 * input_sequences_reshaped.shape[0])\n",
    "#val_size = input_sequences_reshaped.shape[0] - train_size - test_size\n",
    "\n",
    "#X_train = input_sequences_reshaped[:train_size]\n",
    "#X_test = input_sequences_reshaped[train_size:train_size + test_size]\n",
    "#X_val = input_sequences_reshaped[train_size + test_size:]\n",
    "\n",
    "#y_train = output_values_reshaped[:train_size]\n",
    "#y_test = output_values_reshaped[train_size:train_size + test_size]\n",
    "#y_val = output_values_reshaped[train_size + test_size:]\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "print(f\"X_val shape: {X_val.shape}, y_val shape: {y_val.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n",
    "\n",
    "class SaveTrainingDataCallback(dde.callbacks.Callback):\n",
    "    def __init__(self, filename, interval=1000):\n",
    "        self.filename = filename\n",
    "        self.interval = interval\n",
    "        self.history = []\n",
    "        self.model = None\n",
    "\n",
    "    def set_model(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def on_train_begin(self):\n",
    "        print(\"Starting training...\")\n",
    "\n",
    "    def get_learning_rate(self):\n",
    "        # Safeguard to get the learning rate from the optimizer\n",
    "        try:\n",
    "            return self.model.opt.learning_rate.numpy()\n",
    "        except AttributeError:\n",
    "            try:\n",
    "                return self.model.opt.lr.numpy()\n",
    "            except AttributeError:\n",
    "                return None\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        # Save training data at specified intervals\n",
    "        if self.model.train_state.epoch % self.interval == 0:\n",
    "            # Collect data to save\n",
    "            current_data = {\n",
    "                'epoch': self.model.train_state.epoch,\n",
    "                'train_loss': self.model.train_state.loss_train,\n",
    "                'test_loss': self.model.train_state.loss_test,\n",
    "                'metrics': self.model.train_state.metrics_test,\n",
    "                'lr': self.get_learning_rate()\n",
    "            }\n",
    "            self.history.append(current_data)\n",
    "            # Save to file\n",
    "            np.save(self.filename, self.history)\n",
    "            print(f\"Saved training data at epoch {self.model.train_state.epoch}\")\n",
    "\n",
    "    def on_train_end(self):\n",
    "        # Save final training data\n",
    "        np.save(self.filename, self.history)\n",
    "        print(\"Training finished and data saved.\")\n",
    "\n",
    "\n",
    "# Custom data set\n",
    "data = dde.data.DataSet(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_val,\n",
    "    y_val,\n",
    ")\n",
    "\n",
    "print(\"Custom data set defined\")\n",
    "\n",
    "# Construct the neural network with LAAF-10 relu activation\n",
    "activation = \"LAAF-10 relu\"\n",
    "#regularization = [\"l2\", 0.01]\n",
    "net = dde.maps.FNN([input_sequences_reshaped.shape[1]] + [50] * 3 + [output_values_reshaped.shape[1]], activation, \"Glorot uniform\")\n",
    "\n",
    "# Ensure the output layer uses ReLU to prevent negative predictions\n",
    "net.apply_output_transform(lambda x, y: tf.nn.relu(y))\n",
    "\n",
    "# Define the model\n",
    "model = dde.Model(data, net)\n",
    "\n",
    "# Define the PDE residual function\n",
    "def pde_residual(x, y):\n",
    "    return pde(x, y)\n",
    "\n",
    "save_training_data_callback = SaveTrainingDataCallback(filename='C:/Users/Ioannis/Documents/neural-agent-models/data/training_data/PINN(50x50)(82)_train_data.npy', interval=1000)\n",
    "\n",
    "# Compile the model with combined losses: data loss (MSE) and PDE residual loss\n",
    "model.compile(\"adam\", lr=1e-3, metrics=[\"mean squared error\"])\n",
    "\n",
    "# Adding the physics-informed loss component directly into the training process\n",
    "losshistory, train_state = model.train(iterations=10000, display_every=1000, callbacks=[save_training_data_callback])\n",
    "\n",
    "# Plot the loss history\n",
    "dde.utils.plot_loss_history(losshistory)\n",
    "\n",
    "#metrics\n",
    "def mean_absolute_percentage_error(y_true, y_pred, epsilon=1e-10):\n",
    "    return np.mean(np.abs((y_true - y_pred) / np.clip(np.abs(y_true), epsilon, None)))\n",
    "\n",
    "def mean_squared_error(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "def mean_absolute_error(y_true, y_pred):\n",
    "    return np.mean(np.abs(y_true - y_pred))\n",
    "\n",
    "def mean_squared_logarithmic_error(y_true, y_pred):\n",
    "    return np.mean((np.log1p(y_true) - np.log1p(y_pred)) ** 2)\n",
    "\n",
    "def r_squared(y_true, y_pred):\n",
    "    ss_res = np.sum((y_true - y_pred) ** 2)\n",
    "    ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)\n",
    "    return 1 - (ss_res / ss_tot)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    abs_diff = np.abs(y_true - y_pred)\n",
    "    threshold = 0.2 * np.abs(y_true)\n",
    "    accurate_predictions = abs_diff <= threshold\n",
    "    accuracy = np.mean(accurate_predictions)\n",
    "    return accuracy\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Reshape the predictions and true values\n",
    "y_pred_reshaped = y_pred.reshape(y_test.shape[0], 50, 50, 6)\n",
    "y_test_reshaped = y_test.reshape(y_test.shape[0], 50, 50, 6)\n",
    "\n",
    "# Evaluate the model using various metrics\n",
    "mape = mean_absolute_percentage_error(y_test_reshaped, y_pred_reshaped)\n",
    "mse = mean_squared_error(y_test_reshaped, y_pred_reshaped)\n",
    "mae = mean_absolute_error(y_test_reshaped, y_pred_reshaped)\n",
    "msle = mean_squared_logarithmic_error(y_test_reshaped, y_pred_reshaped)\n",
    "r2 = r_squared(y_test_reshaped, y_pred_reshaped)\n",
    "acc = accuracy(y_test_reshaped, y_pred_reshaped)\n",
    "\n",
    "print(\"Mean Absolute Percentage Error (MAPE) on the test set:\", mape)\n",
    "print(\"Mean Squared Error (MSE) on the test set:\", mse)\n",
    "print(\"Mean Absolute Error (MAE) on the test set:\", mae)\n",
    "print(\"Mean Squared Logarithmic Error (MSLE) on the test set:\", msle)\n",
    "print(\"R-squared (RÂ²) on the test set:\", r2)\n",
    "print(\"Accuracy on the test set:\", acc)\n",
    "\n",
    "print(\"y_pred:\", y_pred.shape)\n",
    "print(\"y_pred_flat:\", y_pred_reshaped.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Export the data from the predictions*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction completed\n",
      "y_pred reshaped: (19, 50, 50, 6)\n",
      "y_test reshaped: (19, 50, 50, 6)\n"
     ]
    }
   ],
   "source": [
    "# Reshape predictions back to (19, 50, 50, 6)\n",
    "y_pred_reshaped = y_pred.reshape(y_test.shape[0], 50, 50, 6)\n",
    "y_test_reshaped = y_test.reshape(y_test.shape[0], 50, 50, 6)\n",
    "\n",
    "print(\"Prediction completed\")\n",
    "print(\"y_pred reshaped:\", y_pred_reshaped.shape)\n",
    "print(\"y_test reshaped:\", y_test_reshaped.shape)\n",
    "\n",
    "y_pred = y_pred_reshaped\n",
    "y_test = y_test_reshaped\n",
    "\n",
    "y_pred_shape = y_pred.shape\n",
    "y_test_shape = y_test.shape\n",
    "\n",
    "# Flatten the y_pred and y_test tensors\n",
    "y_pred_flattened = np.reshape(y_pred, (y_pred_shape[0], -1, y_pred_shape[-1]))\n",
    "y_test_flattened = np.reshape(y_test, (y_test_shape[0], -1, y_test_shape[-1]))\n",
    "\n",
    "# Create arrays for x and y coordinates\n",
    "X = np.repeat(np.arange(y_test_shape[1]), y_test_shape[2])\n",
    "Y = np.tile(np.arange(y_test_shape[2]), y_test_shape[1])\n",
    "\n",
    "# Initialize a list to hold all data for the DataFrame\n",
    "all_data = []\n",
    "\n",
    "# Loop through each timestep and collect the data\n",
    "for timestep in range(y_pred_shape[0]):\n",
    "    y_pred_timestep = y_pred_flattened[timestep]\n",
    "    for i in range(y_pred_timestep.shape[0]):\n",
    "        data_point = {'timestep': timestep, 'X': X[i], 'Y': Y[i]}\n",
    "        data_point.update({f'feature_{j+1}': y_pred_timestep[i, j] for j in range(y_pred_shape[-1])})\n",
    "        all_data.append(data_point)\n",
    "\n",
    "# Create the DataFrame\n",
    "df_all_timesteps = pd.DataFrame(all_data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df_all_timesteps.to_csv('C:/Users/Ioannis/Documents/neural-agent-models/data/predictions/predictions(50x50)/PINN(50x50)(82-100hrs).csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Compute the means and std, then plot timeseries for the means of actual vs pred to see general behavior*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine y_test and y_pred for easier range calculation\n",
    "combined_data = np.concatenate([y_test, y_pred])\n",
    "\n",
    "output_dir = 'plots-PINN'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Mask zeros and small values, set lower limit for log scale\n",
    "masked_data = np.ma.masked_equal(combined_data, 0)\n",
    "lower_limit = 1e-13\n",
    "\n",
    "# Calculate min and max values for each cytokine, ignoring zeros and clipping\n",
    "min_values = np.ma.min(masked_data, axis=(0, 1, 2))\n",
    "max_values = np.ma.max(masked_data, axis=(0, 1, 2))\n",
    "\n",
    "# Convert masked arrays to regular arrays with NaN where masked\n",
    "min_values = min_values.filled(np.nan)\n",
    "max_values = max_values.filled(np.nan)\n",
    "\n",
    "# Average over the spatial dimensions (X, Y coordinates)\n",
    "y_test_avg = np.mean(y_test, axis=(1, 2))\n",
    "y_pred_avg = np.mean(y_pred, axis=(1, 2))\n",
    "\n",
    "# Calculate mean and std for each cytokine across all time steps\n",
    "y_test_mean = np.mean(y_test_avg, axis=0)\n",
    "y_pred_mean = np.mean(y_pred_avg, axis=0)\n",
    "y_test_std = np.std(y_test_avg, axis=0)\n",
    "y_pred_std = np.std(y_pred_avg, axis=0)\n",
    "\n",
    "# Time steps (assuming they are from t=82 to t=100)\n",
    "time_steps = np.arange(82, 101)\n",
    "\n",
    "labels = ['il-8', 'il-1', 'il-6', 'il-10', 'tnf', 'tgf']\n",
    "\n",
    "# Plotting\n",
    "fig, axs = plt.subplots(6, 1, figsize=(12, 18), sharex=True)\n",
    "\n",
    "for i in range(6):\n",
    "    axs[i].plot(time_steps, y_test_avg[:, i], label='Actual', marker='o')\n",
    "    axs[i].plot(time_steps, y_pred_avg[:, i], label='Predicted', marker='x')\n",
    "    axs[i].set_title(f'{labels[i]} Concentration over Time\\nMean Â± Std: {y_pred_mean[i]:.2e} Â± {y_pred_std[i]:.2e}')\n",
    "    axs[i].set_ylabel('Concentration (log scale)')\n",
    "    axs[i].set_yscale('log')\n",
    "    axs[i].set_ylim(lower_limit, max_values[i])\n",
    "    axs[i].legend()\n",
    "\n",
    "axs[-1].set_xlabel('Time Step')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# save the plot to the specified folder\n",
    "plot_filename = f'{labels[i]}(t=82 to t=100)(time series plot).png'\n",
    "plot_path = os.path.join(output_dir, plot_filename)\n",
    "plt.savefig(plot_path)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
